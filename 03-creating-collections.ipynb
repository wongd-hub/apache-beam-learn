{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Collections\n",
    "\n",
    "## Creating in-memory `PCollection`s\n",
    "\n",
    "- We can now create rudimentary Beam pipelines and pass parameters into them. Now we'll learn how to create `PCollection`s and fill them with data.\n",
    "- There are a few options for doing this:\n",
    "    - Create a `PCollection` of data stored in an in-memory collection class in your driver program\n",
    "    - Read data from a variety of external sources such as local or cloud-based files or databases using Beam-provided IO adapters\n",
    "\n",
    "To create a `PCollection` from in-memory data, we use the `Create` transform:\n",
    "\n",
    "```python\n",
    "import apache_beam as beam\n",
    "\n",
    "# Output PCollection - don't worry about this, we'll learn this \n",
    "# in future lessons. Just know that this outputs the PCollection\n",
    "class Output(beam.PTransform):\n",
    "    class _OutputFn(beam.DoFn):\n",
    "        def __init__(self, prefix=''):\n",
    "            super().__init__()\n",
    "            self.prefix = prefix\n",
    "\n",
    "        def process(self, element):\n",
    "            print(self.prefix+str(element))\n",
    "\n",
    "    def __init__(self, label=None,prefix=''):\n",
    "        super().__init__(label)\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def expand(self, input):\n",
    "        input | beam.ParDo(self._OutputFn(self.prefix))\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "    (\n",
    "        p\n",
    "        | 'Create range' >> beam.Create(range(1, 11))\n",
    "        | 'Output range' >> Output()\n",
    "    ) \n",
    "\n",
    "    (\n",
    "        p\n",
    "        | 'Create words' >> beam.Create(['To', 'be', 'or', 'not', 'to', 'be'])\n",
    "        | 'Output words' >> Output()\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "To\n",
      "be\n",
      "or\n",
      "not\n",
      "to\n",
      "be\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python source/03-creating-collections-01.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating `PCollection`s from text files\n",
    "\n",
    "You use a Beam-provided IO adapter to read from an external source. They all return a `PCollection`.\n",
    "\n",
    "For example, to read text, we use `TextIO.Read`.\n",
    "\n",
    "```python\n",
    "# Now create the PCollection by reading text files. Separate elements will be added for each line in the input file\n",
    "(p | beam.io.ReadFromText('gs://some/inputData.txt'))\n",
    "```\n",
    "\n",
    "In a pipeline:\n",
    "\n",
    "```python\n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "    input = (\n",
    "        p\n",
    "        | 'Log lines' >> beam.io.ReadFromText('gs://apache-beam-samples/shakespear/kinglear.txt')\n",
    "        | beam.Filter(lambda line: lin != \"\")\n",
    "    )\n",
    "\n",
    "    input\n",
    "\n",
    "    (\n",
    "        input\n",
    "        # Limit output to 10 items\n",
    "        | 'Log fixed lines' >> beam.combiners.Sample.FixedSizeGlobally(10)\n",
    "        | beam.FlatMap(lambda sentence: sentence)\n",
    "        | Output(prefix = 'Fixed first 10 lines:')\n",
    "    )\n",
    "\n",
    "\n",
    "    words = (\n",
    "        p\n",
    "        | 'Log words' >> beam.io.ReadFromText('gs://apache-beam-samples/shakespear/kinglear.txt')\n",
    "        | beam.Filter(lambda word: not word.isspace() or word.isalnum())\n",
    "        | beam.combiners.Sample.FixedSizeGlobally(10) \n",
    "        | beam.FlatMap(lambda word: word)    \n",
    "        | 'Log output words' >> Output(prefix = 'Word: ')\n",
    "    )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating `PCollection`s from CSVs\n",
    "\n",
    "This consists of two main parts:\n",
    "- Using TextIO.Read to load the text lines from the CSV\n",
    "- Parsing lines of text into tabular format\n",
    "\n",
    "```python\n",
    "# Standard DoFn definition, inherit class from beam.DoFn then \n",
    "# write main processing logic inside `process()`\n",
    "class ExtractTaxiRideCostFn(beam.DoFn):\n",
    "\n",
    "    def process(self, element):\n",
    "        line = element.split(',')\n",
    "        return tryParseTaxiRideCost(line,16)\n",
    "\n",
    "# If num of elements in a row > index, then pull the item at \n",
    "# that index, otherwise return 0\n",
    "def tryParseTaxiRideCost(line,index):\n",
    "    if(len(line) > index):\n",
    "        # Using yield here seems to be standard in Beam pipelines, and \n",
    "        # apparently helps with memory-efficiency (since we don't keep \n",
    "        # the entire list in mem, only the next/current item) and optimisation\n",
    "        yield line[index]\n",
    "    else:\n",
    "        yield 0.0\n",
    "\n",
    "# This pipeline\n",
    "with beam.Pipeline() as p:\n",
    "  lines = (\n",
    "    p \n",
    "    | 'Log lines' >> beam.io.ReadFromText('gs://apache-beam-samples/nyc_taxi/misc/sample1000.csv')\n",
    "    | beam.ParDo(ExtractTaxiRideCostFn())\n",
    "    | beam.combiners.Sample.FixedSizeGlobally(10)\n",
    "    | beam.FlatMap(lambda cost: cost)\n",
    "    | Output(prefix = 'Taxi cost: ')\n",
    "  )\n",
    "\n",
    "#> Taxi cost: 9.35\n",
    "#> Taxi cost: 15.38\n",
    "#> Taxi cost: 10.8\n",
    "#> Taxi cost: 9.8\n",
    "#> Taxi cost: 18.55\n",
    "#> Taxi cost: 30.3\n",
    "#> Taxi cost: 6.2\n",
    "#> Taxi cost: 7.3\n",
    "#> Taxi cost: 28.5\n",
    "#> Taxi cost: 5.3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache-beam-learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
